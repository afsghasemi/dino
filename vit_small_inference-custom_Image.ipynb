{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os \r\n",
        "\r\n",
        "import azureml.core\r\n",
        "from azureml.core import Workspace, Dataset, Datastore, Experiment, Environment, ScriptRunConfig\r\n",
        "\r\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "\r\n",
        "from azureml.core.runconfig import PyTorchConfiguration, DockerConfiguration\r\n",
        "from azureml.core.conda_dependencies import CondaDependencies\r\n",
        "\r\n",
        "from azureml.data import OutputFileDatasetConfig\r\n",
        "from azureml.telemetry import set_diagnostics_collection\r\n",
        "from azureml.widgets import RunDetails\r\n",
        "\r\n",
        "set_diagnostics_collection(send_diagnostics=True)\r\n",
        "\r\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Turning diagnostics collection on. \nSDK version: 1.38.0\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1646711518090
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "azureml._restclient.snapshots_client.SNAPSHOT_MAX_SIZE_BYTES = 2000000000"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646711519493
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "project_folder = '../dino'\r\n",
        "ws = Workspace.from_config()\r\n",
        "datastore = ws.get_default_datastore()\r\n",
        "image_net_dataset = Dataset.get_by_name(ws, 'imagenet_2015_premium_west_full')"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646711523089
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# choose a name for your cluster\r\n",
        "cluster_name = 'A100-2'\r\n",
        "try:\r\n",
        "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\r\n",
        "    print('Found existing compute target.')\r\n",
        "except ComputeTargetException:\r\n",
        "    print('Cannot Find the compute cluster')\r\n",
        "\r\n",
        "# use get_status() to get a detailed status for the current AmlCompute. \r\n",
        "print(compute_target.get_status().serialize())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing compute target.\n{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2022-03-08T01:33:47.270000+00:00', 'errors': None, 'creationTime': '2022-03-06T10:48:17.444629+00:00', 'modifiedTime': '2022-03-08T01:13:47.335722+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 2, 'nodeIdleTimeBeforeScaleDown': 'PT30S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_ND96AMSR_A100_V4'}\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646711526088
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# curated_env_name = 'AzureML-pytorch-1.10-ubuntu18.04-py38-cuda11-gpu'\r\n",
        "# pytorch_env = Environment.get(workspace=ws, name=curated_env_name)\r\n",
        "# pytorch_env.environment_variables = {\"AZUREML_DOWNLOAD_CONCURRENCY\":384} \r\n",
        "\r\n",
        "# dino_env = pytorch_env.clone(\"dino_env\")\r\n",
        "\r\n",
        "# conda = CondaDependencies()\r\n",
        "\r\n",
        "# # # add pip packages\r\n",
        "# conda.add_pip_package('timm')\r\n",
        "# # # create environment\r\n",
        "# dino_env.python.conda_dependencies = conda\r\n",
        "# docker_config = DockerConfiguration(use_docker=True, arguments = ['--ipc=host'], shm_size='1.2T')\r\n",
        "\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646701373176
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# curated_env_name = 'PTEBIC-pytorch-1.10-ubuntu18.04-py38-cuda11-gpu'\r\n",
        "# pytorch_env = Environment.get(workspace=ws, name=curated_env_name)\r\n",
        "# pytorch_env.environment_variables = {\"AZUREML_DOWNLOAD_CONCURRENCY\":384, \"NCCL_DEBUG\":\"INFO\", \"NCCL_DEBUG_SUBSYS\":\"ALL\", \"NCCL_ALGO\":\"Tree,Collnet\"} \r\n",
        "\r\n",
        "# dino_env = pytorch_env.clone(\"dino_env\")\r\n",
        "# conda = CondaDependencies()\r\n",
        "# dino_env.python.conda_dependencies = conda\r\n",
        "\r\n",
        "env = Environment(\"sea-dockerfile\")\r\n",
        "env.docker.base_image = \"ptebic.azurecr.io/internal/azureml/aifx/stable-ubuntu2004-cu113-py38-torch1101:latest\"\r\n",
        "env.environment_variables = {\"AZUREML_DOWNLOAD_CONCURRENCY\":384, \"NCCL_DEBUG\":\"INFO\", \"NCCL_DEBUG_SUBSYS\":\"ALL\", \"NCCL_TOPO_FILE\": \"/var/run/nvidia-topologyd/A100/virtualTopology.xml\"} \r\n",
        "env.python.user_managed_dependencies = True\r\n",
        "\r\n",
        "docker_config = DockerConfiguration(use_docker=True, arguments = ['--ipc=host'], shm_size='256g')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING:azureml.core.environment:Property environment_variables is deprecated. Use RunConfiguration.environment_variables to set runtime variables.\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646712066420
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patch_size = 16\r\n",
        "batch_size_per_gpu = 64\r\n",
        "node_count = 1\r\n",
        "process_count = 8\r\n",
        "communication_backend = 'NCCL'"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646712064455
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#datastore = ws.get_default_datastore()\r\n",
        "#out_dataset = Dataset.get_by_name(ws,name='Output_node1_ViTs_gpus8_bacthsize64')\r\n"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646701373482
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference - Linear"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\r\n",
        "experiment_name = 'exp_Inference_ViTS16'\r\n",
        "Inference_experiment = Experiment(ws, name=experiment_name)\r\n",
        "# create distributed config\r\n",
        "distr_Inference_config = PyTorchConfiguration(node_count=node_count)\r\n",
        "#launch_cmd = [\"python -m torch.distributed.launch --nproc_per_node=8 eval_linear.py --pretrained_weights\",'./checkpoints' , \"--checkpoint_key teacher --data_path\", image_net_dataset.as_download(),\"--patch_size 16 --batch_size_per_gpu 64\"]\r\n",
        "launch_cmd = [\"torchrun --nproc_per_node=8 eval_linear.py --pretrained_weights\",'./checkpoints' , \"--checkpoint_key teacher --data_path\", image_net_dataset.as_download(),\"--patch_size 16 --batch_size_per_gpu 64\"]\r\n",
        "\r\n",
        "src_config_linear = ScriptRunConfig(\r\n",
        "  source_directory=project_folder,\r\n",
        "  command=launch_cmd,\r\n",
        "  compute_target=compute_target,\r\n",
        "  environment=env,\r\n",
        "  distributed_job_config=distr_Inference_config\r\n",
        ")\r\n",
        "runInferenceLinear = Inference_experiment.submit(src_config_linear)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING:root:You might see network latency and increased data transfer costs if you chose a cluster in a location different from the location of your workspace\nSubmitting /mnt/batch/tasks/shared/LS_root/mounts/clusters/ds3-4cores/code/Users/aghasemi/dino directory for run. The size of the directory >= 25 MB, so it can take a few minutes.\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646712149704
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "runInferenceLinear.tag(\"author\",\"AFS\")\r\n",
        "runInferenceLinear.tag(\"storage\" , \"premium\")\r\n",
        "runInferenceLinear.tag(\"envoirnment\" ,'dino_env' )\r\n",
        "runInferenceLinear.tag(\"dataset\", \"download\")\r\n",
        "runInferenceLinear.tag(\"batch_size_per_gpu\" , str(batch_size_per_gpu))\r\n",
        "runInferenceLinear.tag(\"patch_size\" , str(patch_size))\r\n",
        "runInferenceLinear.tag(\"epochs\" , \"100\")\r\n",
        "runInferenceLinear.tag(\"ENV\" , str(curated_env_name))\r\n",
        "runInferenceLinear.tag(\"gpus\" , str(process_count))\r\n",
        "runInferenceLinear.tag(\"nodes\" , str(node_count))\r\n"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'curated_env_name' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m runInferenceLinear\u001b[38;5;241m.\u001b[39mtag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m , \u001b[38;5;28mstr\u001b[39m(patch_size))\n\u001b[1;32m      7\u001b[0m runInferenceLinear\u001b[38;5;241m.\u001b[39mtag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m , \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m100\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m runInferenceLinear\u001b[38;5;241m.\u001b[39mtag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENV\u001b[39m\u001b[38;5;124m\"\u001b[39m , \u001b[38;5;28mstr\u001b[39m(\u001b[43mcurated_env_name\u001b[49m))\n\u001b[1;32m      9\u001b[0m runInferenceLinear\u001b[38;5;241m.\u001b[39mtag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpus\u001b[39m\u001b[38;5;124m\"\u001b[39m , \u001b[38;5;28mstr\u001b[39m(process_count))\n\u001b[1;32m     10\u001b[0m runInferenceLinear\u001b[38;5;241m.\u001b[39mtag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnodes\u001b[39m\u001b[38;5;124m\"\u001b[39m , \u001b[38;5;28mstr\u001b[39m(node_count))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'curated_env_name' is not defined"
          ]
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646701468800
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RunDetails(runInferenceLinear).show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646701469065
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualise attention"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %run visualize_attention --pretrained_weights 'checkpoint.pth' --checkpoint_key 'teacher' --image_path 'img.png' --patch_size 16"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\r\n",
        "# fig = plt.figure(figsize=(15, 5))\r\n",
        "# fig.add_subplot(1, 1, 1)\r\n",
        "# img = plt.imread('img.png')\r\n",
        "# plt.imshow(img)\r\n",
        "# fig.add_subplot(1, 2, 1)\r\n",
        "# attn = plt.imread('attn-head0.png')\r\n",
        "# plt.imshow(attn)\r\n",
        "# plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646654073541
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}